\section{Random Ideas}
\subsection{Multi-objective Optimization Formulation}
The above bilevel optimization problem is equivalent to the following multi-objective optimization problem with an additional constraint.

\begin{align}
    \min_{\mechanism, \decision, \newdecision} & \quad \objective(\mechanism, \decision) ~ \text{and} ~ g(\mechanism, \newdecision) \\
    \text{s.t.} & \quad \decision = \newdecision \\ 
    & \quad \decision, \newdecision \in \Decision \\
    & \quad \mechanism \in \Mechanism
\end{align}


One of the most commonly used solutions to multi-objective optimization problem is to apply a weighted sum to multiple objectives to reduce to a single-objective optimization problem:

\begin{align}
    \min_{\mechanism, \decision, \newdecision} & \quad \objective(\mechanism, \decision) + w g(\mechanism, \newdecision) \\
    \text{s.t.} & \quad \decision = \newdecision \\
    & \quad \mechanism \in \Mechanism
\end{align}
where the weight $w$ is a hyper-parameter that can be tuned.
\textcolor{red}{Jimmy: I wonder if some strong regularity condition is required for existence of some $\omega$ to make it work. For the simple Bilevel optimization problem, a sufficiently large $\omega$ should be good.}


\subsection{Nonsmooth formulations}

Considering Eq.~\ref{eqn:two_constraints}, one can replace the two constraints $g(x,y)\leq g^*(x),~h(x,y)\leq0$ by the single constraint 
\[
c(x,y):=\max\{g(x,y)-g^*(x),h(x,y)\}\leq 0~.
\]
Note that whenever $g,h$ are $L$-Lipschitz and $\alpha$-strongly convex, then so is $c$, so good properties (other than smoothness) are preserved. This reduces the Lagrangian based analyses to a single multiplier, which seems good. Also note that we need to evaluate now the gradient of $c$, but this is possible whenever we have 0th+1st order access to $g,g^*,h$, since $\partial \max\{f_1,f_2\}=\mathrm{conv}\{\nabla f_i:f_i\mathrm{~attains~the~max}\}$.



Unrelated but also useful in this context, is that we can probably reduce the dimension dependence of \cite{chen2023bilevel} from $d^{3/2}$ to $d$. Their algorithm uses the gradient-free method of \cite{lin2022gradient} which suffers from a $d^{3/2}$ dependence, while they extend the analysis to hold for inexact zero-order oracles. Using instead the algorithm from \cite{kornowski2023algorithm} would reduce the dimension-dependence to $d$, if we show that this algorithm works with inexact oracles as well. The heart would be showing that \citep{cutkosky2023optimal} works under biased oracles. For a very concise analysis of that algorithm, I recommend the blog post: https://truenobility303.github.io/Optimal-NSNC/ (+ run through google translate if needed).

\subsection{Possibly using prior work via prox point method?}
The work of \cite{sabach2017first} provides an  algorithm for $\min_{x\in \arg\min f(x) + g(x)} \omega(x),$ where $f$ is smooth convex, $g$ is nonsmooth convex, and $\omega$ is smooth and convex. In particular, they prove convergence to an $\epsilon$-additive solution in both the outer and inner level problems at an iteration cost of $\epsilon^{-1}$, with a prox operation per iteration. Currently, it's not entirely clear to me if they allow any $g$ or only prox-friendly $g$. Can we use $g(x)= \delta_{h(x)\leq 0}$ (i.e., the indicator of the desired constraint set) and apply \cite{sabach2017first} directly? Their algorithm requires the use of the prox operator; specifically, to apply their algorithm as a blackbox, we need to understand to what accuracy they need to compute $\min_{x: h(x) \leq 0} \|u-x\|_2^2$ for some fixed $u$. Note that \cite{beck2014first} solves the constrained bilevel problem but seem to be limited to  the constraint set being ``prox-friendly''. Can we extend this to the general (strongly convex) $h$ case? Does \cite{sabach2017first} extend to $\omega$ not strongly convex; they seem to use properties of the resolvent of the gradient, which perhaps has extensions in the weakly convex settings. Also note that \cite{jiang2023conditional} improves upon \cite{sabach2017first}. 