\section{Introduction}\label{sec:introduction}
Bilevel optimization~\cite{bracken1973mathematical, colson2007overview,bard2013practical,sinha2017review}, an important problem in optimization, is defined as follows:
\begin{align*}\numberthis\label[prob]{prob:general-constraints}
     \mbox{minimize}_{x\in \mathcal{X}} ~ F(x) \coloneqq f(x, \ystar(x)) \text{ subject to } ~\ystar(x)\in \arg\min\nolimits_{y\in S(x)} g(x, y).
\end{align*}
Here, the value of the upper-level problem at any point $x$ depends on the solution of the lower-level problem. This framework has recently found numerous applications in meta-learning~\cite{ snell2017prototypical, bertinetto2018meta, rajeswaran2019meta, ji2020convergence}, hyperparameter optimization~\cite{franceschi2018bilevel, shaban2019truncated, feurer2019hyperparameter}, and 
% continual learning~\cite{borsos2020coresets, pham2020contextual}, 
reinforcement learning~\cite{konda1999actor, sutton2018reinforcement, hong2020two,zhang2020bi}.
% , and signal processing~\cite{, , }.  
Its growing importance has spurred increasing efforts towards designing computationally efficient algorithms for it. 

As demonstrated by \cite{ghadimi2018approximation}, a key computational step in algorithms for bilevel optimization is estimating ${dy^*(x)}/{dx}$, the gradient of the lower-level solution. This gradient estimation problem has been extensively studied in differentiable optimization~\cite{amos2017optnet,agrawal2019differentiable} by applying the implicit function theorem to the KKT system of the given problem% , a technique which has found many applications in end-to-end learning \pswt{commenting out to keep the focus on the difficulty of computing the gradient}
~\cite{donti2017task,wilder2019melding,kotary2021end,lee2019meta,tang2022pyepo,bai2019deep}.
However, this technique typically entails computing (or estimating) second-order derivatives, which can be prohibitive in high dimensions~\cite{mehra2021penalty, ji2021bilevel,wang2021learning}.

Recently, \cite{liu2022bome} made a big leap forward towards addressing this computational bottleneck.  %\jz{I would not say that.}
% and is therefore not fully first-order. The convergence of first-order method using differentiable optimization is also under-investigated.
Restricting themselves to the class of unconstrained bilevel optimization, they proposed a fully first-order method with finite-time stationarity guarantees. While a remarkable breakthrough,  \cite{liu2022bome} does not directly extend to the important setting of \textit{constrained} bilevel optimization. This motivates the question: 
\begin{quote}
\centering
    \emph{Can we develop a fully first-order algorithm for constrained bilevel optimization?}
\end{quote}
Besides being natural from the viewpoint of complexity theory, this question is well-grounded
in applications, including Stackelberg models~\cite{simaan1973stackelberg,paruchuri2008playing,chu2014integrated} and mechanism design~\cite{wang2022coordinating,dutting2021optimal},  urban planning~\cite{miao2010modeling,kang2010bilevel} and resource allocation~\cite{xu2013bilevel,gutjahr2016bi,zhang2010bilevel,fathollahi2022bi}, and decision-making under uncertainty~\cite{elmachtoub2022smart,munoz2022bilevel,wilder2019melding}.
% \pswt{State a few constrained blo applications.} 
Our primary contribution is an affirmative answer to the highlighted question. While there have been some other recent works~\cite{khanduri2023linearly, yao2024constrained, lu2024firstorder} on this problem, 
 we believe our notion of stationarity more directly addresses the problem at hand
 % , 
% \jz{rephrase}\pswt{done!}
(cf. \cref{sec:related_work}).  We now summarize our contributions.
% \pswt{filler text just to see how much more space we have filler text just to see how much more space we have filler text just to see how much more space we have filler text just to see how much more space we have filler text just to see how much }
% , we answer this question affirmatively. 
% \pswt{motivate constrained bilevel as well as first-order, pose the question we answer (efficient FO constrained BLO), and segue into the next subsection}
% $S$ is a constraint set for the LL variable $y$ 

\subsection{Our contributions}\label{sec:introduction_main_results}
% We provide the following algorithmic results for constrained bilevel programs.
% \, supplementing our theory with numerical experiments.
% Our contributions can be summarized as follows:
\begin{description}[style=unboxed,leftmargin=0cm, itemsep=.5em, parsep=.3em, topsep=.5em]
\item [{(1)}] \textbf{Convex inequality constraints.} As our first contribution, we design fully first-order algorithms for solving \cref{prob:general-constraints} where the lower-level constraint set $S(x):=\left\{y:h(x,y)\leq0\right\}$  is described by convex inequality constraints, and the upper-level variable is unconstrained. 
By ``fully first-order'', we mean that we use only zeroth and first order oracle access to $f$, $g$, and $h$. 


Our measure of convergence of these algorithms is that of $(\delta,\epsilon)$-stationarity~\cite{goldstein1977optimization}: for a Lipschitz function, we say that a point $x$ is $(\delta,\epsilon)$-stationary if within a $\delta$-ball around $x$ there exists a convex combination of subgradients of the function with norm at most $\epsilon$ (cf. \cref{def:GoldsteinDeltaEpsStationary}). 

\looseness=-1To motivate this notion of convergence, we note that the hyperobjective $F$ (in \cref{prob:general-constraints}) as a function of $x$ could be nonsmooth and nonconvex (and is Lipschitz, as  we later prove). Minimizing such a function in general is well-known to be intractable~\cite{nemirovskij1983problem}, necessitating local notions of stationarity. Indeed, not only is it impossible to attain $\epsilon$-stationarity in finite time~ \cite{zhang2020complexity}, even getting \textit{near} an
approximate stationary point of an arbitrary Lipschitz function is impossible unless
the number of queries has an exponential dependence on the dimension~\cite{kornowski2022oracle}. Consequently, for this function class, $(\delta, \epsilon)$-stationarity has recently emerged to be a natural and algorithmically tractable notion of stationarity~\cite{zhang2020complexity}. We give the following guarantee under  regularity assumptions on $f$, $g$, $h$, and $y^*$. 
% \pswt{is there a word to describe the assumption on $dy^*/dx$ without going into the math? like "constraint qualification" or something?}
% Our algorithm ensures that we converge to a point that satisfies $(\delta,\epsilon)$-stationarity for $F$ in $O(\delta^{-1}\epsilon^{-3})$ iterations, each iteration costing $O(\epsilon^{-1})$.  
\begin{theorem}[Informal; \cref{thm:Lipschitz-min-with-inexact-grad-oracle} combined with \cref{thm:cost_of_computing_ystar_gammastar_inequality}]
    Given \cref{prob:general-constraints} with convex inequality constraints $S(x)=\left\{y:h(x,y)\leq0\right\}$ and unconstrained upper-level variable, under  regularity assumptions on $f$, $g$, $h$, and $y^*$ (\cref{assumption:linEq_smoothness,item:assumption_safe_constraints}), there exists an algorithm, which in $\widetilde{O}(\delta^{-1}\epsilon^{-4})$ oracle calls to $f$, $g$, and $h$, converges to a $(\delta, \epsilon)$-stationary point for $F$. 
\end{theorem} To the best of our knowledge, this is the first result to achieve fully first-order finite-time $(\delta,\epsilon)$-stationarity of the hypergradient for constrained bilevel optimization (cf. \cref{sec:related_work} for a discussion of \cite{yao2024constrained}, which recently solved a related problem). 
To this end, we begin by carefully reformulating \cref{prob:general-constraints} via the penalty method and constructing a fully first-order inexact gradient oracle for the hyperobjective $F$ (cf. \cref{sec:inequality-bilevel}). We then employ this inexact gradient oracle within {an algorithm (\cref{{alg: OIGRM}}) designed to minimize Lipschitz nonsmooth nonconvex functions}
(in particular, $F$). Our proposed algorithm offers the following convergence guarantee.
\begin{theorem}[Informal; \cref{{thm:Lipschitz-min-with-inexact-grad-oracle}}]
    Given Lipschitz $F:\reals^d\to\reals$ 
    % be Lipschitz  
% $F(\bx_0)-\inf F\leq \Delta$
and $\|\widetilde{\nabla} F(\cdot)-\nabla F(\cdot)\|\leq\epsilon$,
% Under the same setting as \citep[Theorem 7.2]{chen2023bilevel},
% suppose that $\mathrm{SGM}$ (as in \citep[Theorem 7.1]{chen2023bilevel}) is set so that $|\tF(\cdot)-\varphi(\cdot)|\leq \zeta$ for $\zeta=\Theta(\delta\epsilon/d)$.
 there exists an algorithm that, in 
% $x^{\out}$ such that $\E[\mathrm{dist}(0,{\partial}_\delta F(x^{\out}))]\leq\epsilon+\alpha$, with
$T=O(\delta^{-1}\epsilon^{-3})$
calls to $\widetilde{\nabla}F$,
% Then running \cref{alg: OIGRM} with
% $D=\Theta\left(\frac{\delta\epsilon^2}{L^2}\right),\eta=\Theta\left(\frac{\delta\epsilon^3}{L^4}\right),\nu=\delta$,
outputs a $(\delta,2\epsilon)$-stationary point of $F$.
% \pswt{Make level of detail of runtime consistent across all inf. theorems}
\end{theorem} While such algorithms using  \emph{exact} gradients already exist~\cite{zhang2020complexity, davis2022gradient}, extending them to the inexact gradient  setting is non-trivial; we leverage recent ideas connecting online learning to nonsmooth nonconvex optimization~\cite{cutkosky2023optimal} (cf. \cref{{sec:nonsmooth}}). With the ubiquity of nonsmooth nonconvex  optimization problems associated with
training modern neural networks, we believe our analysis for this general task can be of independent interest to the broader optimization community.  


% \pswt{motivate this with experiments} 
We also design variants  of the aforementioned algorithm, one of which converges in $\widetilde{O}(d_x \delta^{-1}\epsilon^{-3})$ gradient calls, thus trading off an $\epsilon^{-1}$ factor for a linear dependence on the upper dimension $d_x$, while another is 
% trading off
% Finally, we present a 
more implementation-friendly
% version of this algorithm,
with slightly worse worst-case guarantee (cf. \cref{sec:nonsmooth}).
% for full details).
% \pswt{Guy: would you be able to say a bit more about these?} \gk{Added a brief, what do you think?} <sg!

\item[{(2)}] \textbf{Linear equality constraints.} Next, we study the special setting of \cref{prob:general-constraints} with $S(x):=\left\{y:Ax - By-b=0\right\}$ a linear equality constraint and $\mathcal{X}$ a convex compact set. With appropriate regularity assumptions on $f$ and $g$, the hyperobjective $F$ in this case is smooth as a function of $x$. Inspired by ideas from \cite{kwon2023fully}, we use implicit differentiation of the KKT matrix of a slightly perturbed version of the lower-level problem to design a fully-first order approximation to $\nabla F$. With this inexact gradient oracle in hand,  we then run projected gradient descent, which converges in $\widetilde{O}(\epsilon^{-2})$ iterations for smooth functions. Constructing our first-order approximation entails solving a strongly convex optimization problem on affine constraints, which can be done efficiently (cf. \cref{sec:equality-bilevel}). 
% at a linear rate; therefore,  our total cost for achieving $\epsilon$-stationarity of $F$ is nearly-optimal at $\widetilde{O}(\epsilon^{-2})$. 

\begin{theorem}[Informal; cf. \cref{thm:lineq-cost}]
\label{thm:lineq-cost-inf}
    Given \cref{prob:general-constraints} with linear equality constraints $S(x)=\left\{y:Ax-By-b=0\right\}$ and $\mathcal{X}$ a convex compact set, under regularity assumptions on $f$ and $g$ (\cref{assumption:linEq_smoothness,assumption:eq}), there exists an algorithm, which in $\widetilde{O}(\epsilon^{-2})$  oracle calls to $f$ and $g$, converges to an $\epsilon$-stationary point of $F$. 
\end{theorem}

The current result in literature for the linearly constrained setting is that of \cite{khanduri2023linearly}, which 
involves expensive Hessian computations and 
imposes on the hyperobjective $F$ some \textit{strong regularity assumptions} that are, in general, impossible to verify.
In contrast,  we impose \textit{assumptions solely on the constituent functions $f$ and $g$} (and none directly on $F$), which can be easily verified by the user of our algorithms.
Thus, \Cref{thm:lineq-cost-inf} makes substantial progress on these two fronts.
See \cref{sec:equality-bilevel} for details. 
% \pswt{Make this distinction clearer since it's quite big, imo filler text  filler text  filler text  filler text  filler text  filler text  filler text  filler text  filler text  filler text  filler text  filler text }


% \pswt{A line about the previous best result for lineq}
\end{description}